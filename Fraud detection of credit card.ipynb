{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eebbebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f38b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the dataset.\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv.crdownload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7a3665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11660</th>\n",
       "      <td>19915</td>\n",
       "      <td>1.294875</td>\n",
       "      <td>-0.645847</td>\n",
       "      <td>0.689549</td>\n",
       "      <td>-0.351634</td>\n",
       "      <td>-1.026884</td>\n",
       "      <td>-0.129811</td>\n",
       "      <td>-0.928101</td>\n",
       "      <td>0.114172</td>\n",
       "      <td>0.804717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097462</td>\n",
       "      <td>-0.020893</td>\n",
       "      <td>0.040297</td>\n",
       "      <td>0.159282</td>\n",
       "      <td>0.350705</td>\n",
       "      <td>-0.278351</td>\n",
       "      <td>-0.010354</td>\n",
       "      <td>-0.008003</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11661</th>\n",
       "      <td>19915</td>\n",
       "      <td>1.404683</td>\n",
       "      <td>-0.554883</td>\n",
       "      <td>0.612239</td>\n",
       "      <td>-0.234956</td>\n",
       "      <td>-1.190992</td>\n",
       "      <td>-0.816824</td>\n",
       "      <td>-0.775771</td>\n",
       "      <td>-0.142637</td>\n",
       "      <td>1.121638</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.196110</td>\n",
       "      <td>-0.303562</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.313352</td>\n",
       "      <td>0.473813</td>\n",
       "      <td>-0.276618</td>\n",
       "      <td>-0.024026</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11662</th>\n",
       "      <td>19915</td>\n",
       "      <td>-0.945541</td>\n",
       "      <td>0.479754</td>\n",
       "      <td>1.521916</td>\n",
       "      <td>-1.298658</td>\n",
       "      <td>-0.852548</td>\n",
       "      <td>-0.604029</td>\n",
       "      <td>-0.354686</td>\n",
       "      <td>0.498106</td>\n",
       "      <td>0.407159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050745</td>\n",
       "      <td>0.056031</td>\n",
       "      <td>-0.055584</td>\n",
       "      <td>0.312195</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>-0.413466</td>\n",
       "      <td>0.189152</td>\n",
       "      <td>0.086360</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11663</th>\n",
       "      <td>19915</td>\n",
       "      <td>-0.087909</td>\n",
       "      <td>0.184093</td>\n",
       "      <td>1.683910</td>\n",
       "      <td>-0.837378</td>\n",
       "      <td>-0.682605</td>\n",
       "      <td>-0.669907</td>\n",
       "      <td>-0.056222</td>\n",
       "      <td>-0.120669</td>\n",
       "      <td>0.409636</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109428</td>\n",
       "      <td>-0.054760</td>\n",
       "      <td>-0.139329</td>\n",
       "      <td>0.333267</td>\n",
       "      <td>0.072695</td>\n",
       "      <td>-0.320292</td>\n",
       "      <td>0.006423</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11664</th>\n",
       "      <td>19915</td>\n",
       "      <td>1.504229</td>\n",
       "      <td>-0.499337</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>-0.576345</td>\n",
       "      <td>-0.393971</td>\n",
       "      <td>0.015149</td>\n",
       "      <td>-0.718603</td>\n",
       "      <td>-0.125852</td>\n",
       "      <td>1.023281</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11665 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0          0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1          0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2          1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3          1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4          2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...      ...       ...       ...       ...       ...       ...       ...   \n",
       "11660  19915  1.294875 -0.645847  0.689549 -0.351634 -1.026884 -0.129811   \n",
       "11661  19915  1.404683 -0.554883  0.612239 -0.234956 -1.190992 -0.816824   \n",
       "11662  19915 -0.945541  0.479754  1.521916 -1.298658 -0.852548 -0.604029   \n",
       "11663  19915 -0.087909  0.184093  1.683910 -0.837378 -0.682605 -0.669907   \n",
       "11664  19915  1.504229 -0.499337  0.052377 -0.576345 -0.393971  0.015149   \n",
       "\n",
       "             V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0      0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1     -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2      0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3      0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4      0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "11660 -0.928101  0.114172  0.804717  ... -0.097462 -0.020893  0.040297   \n",
       "11661 -0.775771 -0.142637  1.121638  ... -0.196110 -0.303562  0.005661   \n",
       "11662 -0.354686  0.498106  0.407159  ... -0.050745  0.056031 -0.055584   \n",
       "11663 -0.056222 -0.120669  0.409636  ... -0.109428 -0.054760 -0.139329   \n",
       "11664 -0.718603 -0.125852  1.023281  ...       NaN       NaN       NaN   \n",
       "\n",
       "            V24       V25       V26       V27       V28  Amount  Class  \n",
       "0      0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62    0.0  \n",
       "1     -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69    0.0  \n",
       "2     -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66    0.0  \n",
       "3     -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50    0.0  \n",
       "4      0.141267 -0.206010  0.502292  0.219422  0.215153   69.99    0.0  \n",
       "...         ...       ...       ...       ...       ...     ...    ...  \n",
       "11660  0.159282  0.350705 -0.278351 -0.010354 -0.008003   10.00    0.0  \n",
       "11661  0.313352  0.473813 -0.276618 -0.024026  0.002106    5.00    0.0  \n",
       "11662  0.312195  0.026299 -0.413466  0.189152  0.086360   10.00    0.0  \n",
       "11663  0.333267  0.072695 -0.320292  0.006423  0.010148   10.00    0.0  \n",
       "11664       NaN       NaN       NaN       NaN       NaN     NaN    NaN  \n",
       "\n",
       "[11665 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e3b01ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       1\n",
       "V13       1\n",
       "V14       1\n",
       "V15       1\n",
       "V16       1\n",
       "V17       1\n",
       "V18       1\n",
       "V19       1\n",
       "V20       1\n",
       "V21       1\n",
       "V22       1\n",
       "V23       1\n",
       "V24       1\n",
       "V25       1\n",
       "V26       1\n",
       "V27       1\n",
       "V28       1\n",
       "Amount    1\n",
       "Class     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Performing missing values analysis\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "747b3634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d93aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf317d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9c4ff8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb725f",
   "metadata": {},
   "source": [
    "### From the dataset, calculate the number of genuine transactions, number of fraud transactions and the percentage of fraud transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11e32478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of genuine transactions\n",
    "\n",
    "num_gen_trans = len(df[df['Class'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9da1af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11615"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gen_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d44d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75563460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the num of fraud transactions\n",
    "\n",
    "num_fraud_trans = len(df[df['Class'] == 1])\n",
    "num_fraud_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ef3d5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4200960219478738"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the % of fraud transactions\n",
    "\n",
    "Percentage_ft = (num_fraud_trans / len(df)) * 100\n",
    "Percentage_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "561bb90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Genuine transactions:  11615\n",
      "Number of Fraud transactions:  49\n",
      "Percentage of Fraud transactions: 0.4201\n"
     ]
    }
   ],
   "source": [
    "# Another method\n",
    "\n",
    "non_fraud = len(df[df.Class == 0])\n",
    "fraud = len(df[df.Class == 1])\n",
    "fraud_percent = (fraud / (fraud + non_fraud)) * 100\n",
    "print(\"Number of Genuine transactions: \", non_fraud)\n",
    "print(\"Number of Fraud transactions: \", fraud)\n",
    "print(\"Percentage of Fraud transactions: {:.4f}\".format(fraud_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa32a071",
   "metadata": {},
   "source": [
    "### 4. Using the visualization module, visualize the genuine and fraudulent transactions using a bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fba98f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    11615\n",
      "1.0       49\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['Class'].value_counts()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35220bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAJdCAYAAADAwuq4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABMdElEQVR4nO3deViU9f7/8deIbCKMIgJiqGjuS7mUop3U3BU5thzrUKgd08otco3TovYrLSv1lGt1ypO51EntWBlpappHUVLRVNTcNUVMYVBDQLh/f/jlPs09aGroAD4f1zXX1Xzu99zzvoellx8+8xmbYRiGAAAAAJjKuLsBAAAAoLghJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkA6XQ9u3b1b9/f9WqVUu+vr7y9fVV7dq19eSTT+qHH35wd3um7777TjabTd999527W/ld27dvl81m09atW//QeWw2W6G3oKCgIur0j/sjX5dDhw7JZrNpzpw5Rd7Xb82fP19Tp0696voZM2bc8J6Ko/Xr12vcuHHKyMhwOdauXTu1a9fupvcElBRl3d0AgKI1e/ZsDRkyRHXr1tUzzzyjhg0bymazKSUlRQsWLNBdd92lffv2qVatWu5uVc2aNdOGDRvUoEEDd7fyuxYtWqSIiAg1bdr0D5/roYce0ogRI5zGPD09//B5byXz58/Xjh07FBcXd1X1M2bMUFBQkPr163dD+ypu1q9fr/Hjx6tfv36qUKGC07EZM2a4pymghCAkA6XIf//7Xw0aNEg9evTQZ599Ji8vL/PYfffdp8GDB+vf//63fH193djl/wQEBKhVq1bubuOqfPbZZ3rwwQeL5FwhISHXdN1ZWVnF5mt2K8jNzZXNZlPZsqX7f5El4R+ngDux3AIoRSZMmCAPDw/Nnj3bKSD/1l/+8heFhYU5jf3www+Kjo5WYGCgfHx81LRpU3366adONXPmzJHNZtPq1av19NNPKygoSJUqVdIDDzyg48ePO9XabDaNGzfO5blr1KjhNJNX2J/1+/Xrp/Lly2vfvn3q3r27ypcvr/DwcI0YMULZ2dlO58vJydErr7yievXqydvbW5UrV9bjjz+uU6dOXfF1mjp1qmw2m/bt2+dybMyYMfLy8tIvv/xiju3evVu7du1yCskzZ87UHXfcofLly8vf31/16tXT3//+9ys+79WoUaOGoqKitHjxYjVt2lQ+Pj4aP368JGn69Om69957FRwcLD8/PzVu3FiTJk1Sbm6uyzkKmzEt7M/ru3fvVteuXVWuXDkFBQXpqaee0tmzZwvt62rPWZiffvpJMTExCg4Olre3t+rXr6/p06c71RR8PyxYsEDPP/+8wsLCFBAQoI4dO2rPnj1Oz/nVV1/p8OHDTktWLqdGjRrauXOn1qxZY9bWqFHD6Tnnzp2rESNGqGrVqvL29ta+fft06tQpDRo0SA0aNFD58uUVHBys++67T99//73T+QuWmLz55puaPHmyIiIiVL58eUVGRioxMdGp9sCBA3rkkUcUFhYmb29vhYSEqEOHDkpOTjZrPvnkE3Xu3FlVqlSRr6+v6tevr+eee07nz593ubaNGzeqZ8+eqlSpknx8fFSrVi1zdn3cuHEaNWqUJCkiIsK89oKft8K+dmfOnNGgQYNUtWpVeXl5qWbNmnr++eddfvZsNpuGDBmiuXPnqn79+ipXrpzuuOMOffnll051p06d0sCBAxUeHm7+jLZp00bffvvtZb9eQHFRuv+ZDNxC8vLytHr1arVo0UJVqlS56setXr1aXbt2VcuWLTVr1izZ7XYtXLhQDz/8sH799VeXYPTEE0+oR48emj9/vo4ePapRo0bpscce06pVq4rsWnJzcxUdHa3+/ftrxIgRWrt2rf7f//t/stvteumllyRJ+fn5+vOf/6zvv/9eo0ePVuvWrXX48GGNHTtW7dq10w8//HDZ2dfHHntMY8aM0Zw5c/TKK6+Y43l5efr444/Vs2dPpzXCixYtUtWqVdWyZUtJ0sKFCzVo0CANHTpUb775psqUKaN9+/Zp165dV3V9hmHo4sWLTmMeHh5m0NuyZYtSUlL0wgsvKCIiQn5+fpKk/fv3KyYmRhEREfLy8tK2bdv06quvavfu3frggw+u8tX9n5MnT6pt27by9PTUjBkzFBISonnz5mnIkCHXfK4r2bVrl1q3bq1q1arprbfeUmhoqL755hsNGzZMv/zyi8aOHetU//e//11t2rTR+++/r8zMTI0ZM0Y9e/ZUSkqKPDw8NGPGDA0cOFD79+/XkiVLfvf5lyxZooceekh2u91cYuDt7e1UEx8fr8jISM2aNUtlypRRcHCw+Y+tsWPHKjQ0VOfOndOSJUvUrl07rVy50iVgTp8+XfXq1TPXSr/44ovq3r27Dh48KLvdLknq3r278vLyNGnSJFWrVk2//PKL1q9f77Rm+KefflL37t0VFxcnPz8/7d69W6+//ro2bdrk9HP2zTffqGfPnqpfv74mT56satWq6dChQ1q+fLmkSz+rZ86c0TvvvKPFixebvxcuN4N84cIFtW/fXvv379f48ePVpEkTff/995o4caKSk5P11VdfOdV/9dVXSkpK0ssvv6zy5ctr0qRJuv/++7Vnzx7VrFlTkhQbG6stW7bo1VdfVZ06dZSRkaEtW7bo9OnTv/t1A9zOAFAqpKamGpKMRx55xOXYxYsXjdzcXPOWn59vHqtXr57RtGlTIzc31+kxUVFRRpUqVYy8vDzDMAzjww8/NCQZgwYNcqqbNGmSIck4ceKEOSbJGDt2rEsf1atXN/r27WveX716tSHJWL16tTnWt29fQ5Lx6aefOj22e/fuRt26dc37CxYsMCQZixYtcqpLSkoyJBkzZsxwef7feuCBB4zbbrvNvD7DMIxly5YZkowvvvjCqfbOO+80hg4dat4fMmSIUaFChSue/3IkFXp77733DMO49Bp5eHgYe/bsueJ58vLyjNzcXOOjjz4yPDw8jDNnzpjHrK9zgbZt2xpt27Y1748ZM8aw2WxGcnKyU12nTp1cvi5Xe86DBw8akowPP/zQHOvSpYtx2223GQ6Hw+mxQ4YMMXx8fMzeC74funfv7lT36aefGpKMDRs2mGM9evQwqlev7tLP5TRs2NCpzwIFz3nvvff+7jkKfo46dOhg3H///eZ4wTU3btzYuHjxojm+adMmQ5KxYMECwzAM45dffjEkGVOnTr3qvvPz843c3FxjzZo1hiRj27Zt5rFatWoZtWrVMrKysi77+DfeeMOQZBw8eNDlmPVrN2vWrEJ/9l5//XVDkrF8+XJzTJIREhJiZGZmmmOpqalGmTJljIkTJ5pj5cuXN+Li4q76eoHihOUWwC2gefPm8vT0NG9vvfWWJGnfvn3avXu3Hn30UUnSxYsXzVv37t114sQJpz9zS1J0dLTT/SZNmkiSDh8+XGT92mw29ezZ0+V5fvscX375pSpUqKCePXs69X3nnXcqNDT0d3dmePzxx3Xs2DGnP/t++OGHCg0NVbdu3cyxAwcOKDk52Wmpxd13362MjAz99a9/1X/+8x+npRlXo3fv3kpKSnK69erVy+la69Sp4/K4rVu3Kjo6WpUqVZKHh4c8PT3Vp08f5eXlae/evdfUg3TprwgNGzbUHXfc4TQeExNzzee6nAsXLmjlypW6//77Va5cOZfvsQsXLrgsSbgZ32NWl1tvPmvWLDVr1kw+Pj4qW7asPD09tXLlSqWkpLjU9ujRQx4eHuZ9a9+BgYGqVauW3njjDU2ePFlbt25Vfn6+y3kOHDigmJgYhYaGml/ntm3bSpL5vHv37tX+/fvVv39/+fj4/LGL/z+rVq2Sn5+fHnroIafxgr8mrVy50mm8ffv28vf3N++HhIQoODjY6et09913m3+xSUxMdFkaBBRnhGSglAgKCpKvr2+hQWL+/PlKSkrS0qVLncZPnjwpSRo5cqRTiPb09NSgQYMkySUAVqpUyel+wZ+ts7KyiuxaypUr5/I/fm9vb124cMGp94yMDHl5ebn0npqa+rvBtVu3bqpSpYo+/PBDSVJ6erqWLl2qPn36OAWdzz77TMHBwbrnnnvMsdjYWH3wwQc6fPiwHnzwQQUHB6tly5ZasWLFVV1f5cqV1aJFC6fbb5d3FLZc5siRI/rTn/6kn3/+Wf/4xz/0/fffKykpyVzXez2v/+nTpxUaGuoyXtjY9Tp9+rQuXryod955x+Xr1L17d0nu+R6zKuw1nzx5sp5++mm1bNlSixYtUmJiopKSktS1a9dCe/m9vm02m1auXKkuXbpo0qRJatasmSpXrqxhw4aZ68DPnTunP/3pT9q4caNeeeUVfffdd0pKStLixYudzlWwFOS2224rolfgf98P1vXdwcHBKlu2rMsSCev1Flzzb1+bTz75RH379tX777+vyMhIBQYGqk+fPkpNTS2yvoEbhTXJQCnh4eGh++67T8uXL9eJEyec/qdfsAbx0KFDTo8pCGbx8fF64IEHCj1v3bp1r7kXb29vlzf6SCrSdYgFbxxMSEgo9PhvZ7gK4+HhodjYWL399tvKyMjQ/PnzlZ2drccff9ypbtGiRerVq5dTcJYuzUQ//vjjOn/+vNauXauxY8cqKipKe/fuVfXq1f/QtRX2JrTPP/9c58+f1+LFi53O/9s3fBXw8fEp9PX/5ZdfnMJ4pUqVCg0rhY1d7TmtKlasaL7WgwcPLrQmIiLiso+/WQp7zT/++GO1a9dOM2fOdBov7I2NV6t69er65z//KenSbPCnn36qcePGKScnR7NmzdKqVat0/Phxfffdd+bssSSXfY4rV64sSTp27Nh192JVqVIlbdy4UYZhOL0eaWlpunjx4nXt5R0UFKSpU6dq6tSpOnLkiJYuXarnnntOaWlpl/3ZBYoLZpKBUiQ+Pl55eXl66qmnrurPmnXr1lXt2rW1bds2l5nNgtvvhc3C1KhRQ9u3b3caW7Vqlc6dO3fN57qcqKgonT59Wnl5eYX2fTXh/vHHH9eFCxe0YMECzZkzR5GRkapXr555/OjRo0pKSrri1m9+fn7q1q2bnn/+eeXk5Gjnzp1Fcn1WBaHlt284MwxD7733nkttYa//3r17XZbOtG/fXjt37tS2bducxufPn3/d57QqV66c2rdvr61bt6pJkyaFfq0Km5H8PdYZy6Kuly695tY3+G3fvl0bNmy4pvNcTp06dfTCCy+ocePG2rJli/mcBf3+1uzZs10eW6tWLX3wwQeF/uOlwLXMwnfo0EHnzp3T559/7jT+0Ucfmcf/iGrVqmnIkCHq1KmTeb1AccZMMlCKtGnTRtOnT9fQoUPVrFkzDRw4UA0bNlSZMmV04sQJLVq0SNKl/YkLzJ49W926dVOXLl3Ur18/Va1aVWfOnFFKSoq2bNmif//739fcR2xsrF588UW99NJLatu2rXbt2qVp06aZ7/AvCo888ojmzZun7t2765lnntHdd98tT09PHTt2TKtXr9af//xn3X///Vc8R7169RQZGamJEyfq6NGjevfdd52OL1q0SBUqVFD79u2dxgcMGCBfX1+1adNGVapUUWpqqiZOnCi73a677rqryK7xtzp16iQvLy/99a9/1ejRo3XhwgXNnDlT6enpLrWxsbF67LHHNGjQID344IM6fPiwJk2aZM4+FoiLi9MHH3ygHj166JVXXjF3t9i9e/d1n7Mw//jHP3TPPffoT3/6k55++mnVqFFDZ8+e1b59+/TFF19c184ojRs31uLFizVz5kw1b95cZcqUUYsWLa5Yv3DhQn3yySeqWbOmfHx81Lhx4ys+R1RUlP7f//t/Gjt2rNq2bas9e/bo5ZdfVkREhMvuJFdj+/btGjJkiP7yl7+odu3a8vLy0qpVq7R9+3Y999xzkqTWrVurYsWKeuqppzR27Fh5enpq3rx5Lv+QkS7tptGzZ0+1atVKzz77rKpVq6YjR47om2++0bx588zrli59Dfr27StPT0/VrVu30H/89unTR9OnT1ffvn116NAhNW7cWOvWrdOECRPUvXt3dezY8Zqu1+FwqH379oqJiVG9evXk7++vpKQkJSQkXPYvV0Cx4u53DgIoesnJycbjjz9uREREGN7e3oaPj49x++23G3369DFWrlzpUr9t2zajd+/eRnBwsOHp6WmEhoYa9913nzFr1iyzpmB3i6SkJKfHFrZDRXZ2tjF69GgjPDzc8PX1Ndq2bWskJydf9e4Wfn5+Lj2OHTvWsP7Kys3NNd58803jjjvuMHx8fIzy5csb9erVM5588knjp59+uqrX6t133zUkGb6+vi67L9xzzz2F7ujwr3/9y2jfvr0REhJieHl5GWFhYUbv3r2N7du3/+7zSTIGDx582ePVq1c3evToUeixL774wrzWqlWrGqNGjTK+/vprl9cwPz/fmDRpklGzZk3Dx8fHaNGihbFq1SqX3QwMwzB27dpldOrUyfDx8TECAwON/v37G//5z3+u+5yF7W5RMP63v/3NqFq1quHp6WlUrlzZaN26tfHKK6+YNQXfD//+979dHms955kzZ4yHHnrIqFChgmGz2Vy+N6wOHTpkdO7c2fD39zckmTtjXO45DePS9/HIkSONqlWrGj4+PkazZs2Mzz//3Ojbt6/TzhoF/b3xxhsu59Bvdno5efKk0a9fP6NevXqGn5+fUb58eaNJkybGlClTnHbFWL9+vREZGWmUK1fOqFy5svHEE08YW7ZsKfR13bBhg9GtWzfDbrcb3t7eRq1atYxnn33WqSY+Pt4ICwszypQp4/R1Lez74fTp08ZTTz1lVKlSxShbtqxRvXp1Iz4+3rhw4YLLdRX2ffzbn/ELFy4YTz31lNGkSRMjICDA8PX1NerWrWuMHTvWOH/+vMtjgeLGZhiGcZNzOQAUe6mpqapatao+//xzl502AAClHyEZAAAAsOCNewAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIJ9kotQfn6+jh8/Ln9//0I/vQkAAADuZRiGzp49q7CwMJUpc/n5YkJyETp+/LjCw8Pd3QYAAAB+x9GjR3Xbbbdd9jghuQgVfILR0aNHnT7RDAAAAMVDZmamwsPDC/3kyd8iJBehgiUWAQEBhGQAAIBi7PeWxvLGPQAAAMDCrSF57dq16tmzp8LCwmSz2fT555+bx3JzczVmzBg1btxYfn5+CgsLU58+fXT8+HGnc2RnZ2vo0KEKCgqSn5+foqOjdezYMaea9PR0xcbGym63y263KzY2VhkZGU41R44cUc+ePeXn56egoCANGzZMOTk5N+rSAQAAUIy5NSSfP39ed9xxh6ZNm+Zy7Ndff9WWLVv04osvasuWLVq8eLH27t2r6Ohop7q4uDgtWbJECxcu1Lp163Tu3DlFRUUpLy/PrImJiVFycrISEhKUkJCg5ORkxcbGmsfz8vLUo0cPnT9/XuvWrdPChQu1aNEijRgx4sZdPAAAAIotm2EYhrubkC6tC1myZIl69ep12ZqkpCTdfffdOnz4sKpVqyaHw6HKlStr7ty5evjhhyX9b4eJZcuWqUuXLkpJSVGDBg2UmJioli1bSpISExMVGRmp3bt3q27duvr6668VFRWlo0ePKiwsTJK0cOFC9evXT2lpaVe9vjgzM1N2u10Oh4M1yQAAAMXQ1ea1ErUm2eFwyGazqUKFCpKkzZs3Kzc3V507dzZrwsLC1KhRI61fv16StGHDBtntdjMgS1KrVq1kt9udaho1amQGZEnq0qWLsrOztXnz5sv2k52drczMTKcbAAAASr4SE5IvXLig5557TjExMWbqT01NlZeXlypWrOhUGxISotTUVLMmODjY5XzBwcFONSEhIU7HK1asKC8vL7OmMBMnTjTXOdvtdvZIBgAAKCVKREjOzc3VI488ovz8fM2YMeN36w3DcNrWo7AtPq6nxio+Pl4Oh8O8HT169Hd7AwAAQPFX7ENybm6uevfurYMHD2rFihVOa0dCQ0OVk5Oj9PR0p8ekpaWZM8OhoaE6efKky3lPnTrlVGOdMU5PT1dubq7LDPNveXt7m3siszcyAABA6VGsQ3JBQP7pp5/07bffqlKlSk7HmzdvLk9PT61YscIcO3HihHbs2KHWrVtLkiIjI+VwOLRp0yazZuPGjXI4HE41O3bs0IkTJ8ya5cuXy9vbW82bN7+RlwgAAIBiyK2fuHfu3Dnt27fPvH/w4EElJycrMDBQYWFheuihh7RlyxZ9+eWXysvLM2d7AwMD5eXlJbvdrv79+2vEiBGqVKmSAgMDNXLkSDVu3FgdO3aUJNWvX19du3bVgAEDNHv2bEnSwIEDFRUVpbp160qSOnfurAYNGig2NlZvvPGGzpw5o5EjR2rAgAHMDgMAANyC3LoF3Hfffaf27du7jPft21fjxo1TREREoY9bvXq12rVrJ+nSG/pGjRql+fPnKysrSx06dNCMGTOc3kR35swZDRs2TEuXLpUkRUdHa9q0aeYuGdKlDxMZNGiQVq1aJV9fX8XExOjNN9+Ut7f3VV8PW8ABAAAUb1eb14rNPsmlASEZAACgeCuV+yQDAAAANwMhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGDh1k/cAyTJNt7m7hZwizDGsi08AODqMJMMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYuDUkr127Vj179lRYWJhsNps+//xzp+OGYWjcuHEKCwuTr6+v2rVrp507dzrVZGdna+jQoQoKCpKfn5+io6N17Ngxp5r09HTFxsbKbrfLbrcrNjZWGRkZTjVHjhxRz5495efnp6CgIA0bNkw5OTk34rIBAABQzLk1JJ8/f1533HGHpk2bVujxSZMmafLkyZo2bZqSkpIUGhqqTp066ezZs2ZNXFyclixZooULF2rdunU6d+6coqKilJeXZ9bExMQoOTlZCQkJSkhIUHJysmJjY83jeXl56tGjh86fP69169Zp4cKFWrRokUaMGHHjLh4AAADFls0wDMPdTUiSzWbTkiVL1KtXL0mXZpHDwsIUFxenMWPGSLo0axwSEqLXX39dTz75pBwOhypXrqy5c+fq4YcfliQdP35c4eHhWrZsmbp06aKUlBQ1aNBAiYmJatmypSQpMTFRkZGR2r17t+rWrauvv/5aUVFROnr0qMLCwiRJCxcuVL9+/ZSWlqaAgICruobMzEzZ7XY5HI6rfgwk23ibu1vALcIYWyx+3QEA3Ohq81qxXZN88OBBpaamqnPnzuaYt7e32rZtq/Xr10uSNm/erNzcXKeasLAwNWrUyKzZsGGD7Ha7GZAlqVWrVrLb7U41jRo1MgOyJHXp0kXZ2dnavHnzZXvMzs5WZmam0w0AAAAlX7ENyampqZKkkJAQp/GQkBDzWGpqqry8vFSxYsUr1gQHB7ucPzg42KnG+jwVK1aUl5eXWVOYiRMnmuuc7Xa7wsPDr/EqAQAAUBwV25BcwGZz/lO8YRguY1bWmsLqr6fGKj4+Xg6Hw7wdPXr0in0BAACgZCi2ITk0NFSSXGZy09LSzFnf0NBQ5eTkKD09/Yo1J0+edDn/qVOnnGqsz5Oenq7c3FyXGebf8vb2VkBAgNMNAAAAJV+xDckREREKDQ3VihUrzLGcnBytWbNGrVu3liQ1b95cnp6eTjUnTpzQjh07zJrIyEg5HA5t2rTJrNm4caMcDodTzY4dO3TixAmzZvny5fL29lbz5s1v6HUCAACg+Cnrzic/d+6c9u3bZ94/ePCgkpOTFRgYqGrVqikuLk4TJkxQ7dq1Vbt2bU2YMEHlypVTTEyMJMlut6t///4aMWKEKlWqpMDAQI0cOVKNGzdWx44dJUn169dX165dNWDAAM2ePVuSNHDgQEVFRalu3bqSpM6dO6tBgwaKjY3VG2+8oTNnzmjkyJEaMGAAs8MAAAC3ILeG5B9++EHt27c37w8fPlyS1LdvX82ZM0ejR49WVlaWBg0apPT0dLVs2VLLly+Xv7+/+ZgpU6aobNmy6t27t7KystShQwfNmTNHHh4eZs28efM0bNgwcxeM6Ohop72ZPTw89NVXX2nQoEFq06aNfH19FRMTozfffPNGvwQAAAAohorNPsmlAfskXx/2ScbNwj7JAIASv08yAAAA4C6EZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWxTokX7x4US+88IIiIiLk6+urmjVr6uWXX1Z+fr5ZYxiGxo0bp7CwMPn6+qpdu3bauXOn03mys7M1dOhQBQUFyc/PT9HR0Tp27JhTTXp6umJjY2W322W32xUbG6uMjIybcZkAAAAoZop1SH799dc1a9YsTZs2TSkpKZo0aZLeeOMNvfPOO2bNpEmTNHnyZE2bNk1JSUkKDQ1Vp06ddPbsWbMmLi5OS5Ys0cKFC7Vu3TqdO3dOUVFRysvLM2tiYmKUnJyshIQEJSQkKDk5WbGxsTf1egEAAFA82AzDMNzdxOVERUUpJCRE//znP82xBx98UOXKldPcuXNlGIbCwsIUFxenMWPGSLo0axwSEqLXX39dTz75pBwOhypXrqy5c+fq4YcfliQdP35c4eHhWrZsmbp06aKUlBQ1aNBAiYmJatmypSQpMTFRkZGR2r17t+rWrVtof9nZ2crOzjbvZ2ZmKjw8XA6HQwEBATfqZSl1bONt7m4BtwhjbLH9dQcAuEkyMzNlt9t/N68V65nke+65RytXrtTevXslSdu2bdO6devUvXt3SdLBgweVmpqqzp07m4/x9vZW27ZttX79eknS5s2blZub61QTFhamRo0amTUbNmyQ3W43A7IktWrVSna73awpzMSJE83lGXa7XeHh4UV38QAAAHCbsu5u4ErGjBkjh8OhevXqycPDQ3l5eXr11Vf117/+VZKUmpoqSQoJCXF6XEhIiA4fPmzWeHl5qWLFii41BY9PTU1VcHCwy/MHBwebNYWJj4/X8OHDzfsFM8kAAAAo2Yp1SP7kk0/08ccfa/78+WrYsKGSk5MVFxensLAw9e3b16yz2Zz/XG8YhsuYlbWmsPrfO4+3t7e8vb2v9nIAAABQQhTrkDxq1Cg999xzeuSRRyRJjRs31uHDhzVx4kT17dtXoaGhki7NBFepUsV8XFpamjm7HBoaqpycHKWnpzvNJqelpal169ZmzcmTJ12e/9SpUy6z1AAAACj9ivWa5F9//VVlyji36OHhYW4BFxERodDQUK1YscI8npOTozVr1pgBuHnz5vL09HSqOXHihHbs2GHWREZGyuFwaNOmTWbNxo0b5XA4zBoAAADcOor1THLPnj316quvqlq1amrYsKG2bt2qyZMn629/+5ukS0sk4uLiNGHCBNWuXVu1a9fWhAkTVK5cOcXExEiS7Ha7+vfvrxEjRqhSpUoKDAzUyJEj1bhxY3Xs2FGSVL9+fXXt2lUDBgzQ7NmzJUkDBw5UVFTUZXe2AAAAQOlVrEPyO++8oxdffFGDBg1SWlqawsLC9OSTT+qll14ya0aPHq2srCwNGjRI6enpatmypZYvXy5/f3+zZsqUKSpbtqx69+6trKwsdejQQXPmzJGHh4dZM2/ePA0bNszcBSM6OlrTpk27eRcLAACAYqNY75Nc0lztvntwxj7JuFnYJxkAUCr2SQYAAADcgZAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALC4rpBcs2ZNnT592mU8IyNDNWvW/MNNAQAAAO50XSH50KFDysvLcxnPzs7Wzz///IebAgAAANyp7LUUL1261Pzvb775Rna73byfl5enlStXqkaNGkXWHAAAAOAO1xSSe/XqJUmy2Wzq27ev0zFPT0/VqFFDb731VpE1BwAAALjDNYXk/Px8SVJERISSkpIUFBR0Q5oCAAAA3OmaQnKBgwcPFnUfAAAAQLFxXSFZklauXKmVK1cqLS3NnGEu8MEHH/zhxgAAAAB3ua6QPH78eL388stq0aKFqlSpIpvNVtR9AQAAAG5zXSF51qxZmjNnjmJjY4u6HwAAAMDtrmuf5JycHLVu3bqoewEAAACKhesKyU888YTmz59f1L0AAAAAxcJ1Lbe4cOGC3n33XX377bdq0qSJPD09nY5Pnjy5SJoDAAAA3OG6QvL27dt15513SpJ27NjhdIw38QEAAKCku66QvHr16qLuAwAAACg2rmtNMgAAAFCaXddMcvv27a+4rGLVqlXX3RAAAADgbtcVkgvWIxfIzc1VcnKyduzYob59+xZFXwAAAIDbXFdInjJlSqHj48aN07lz5/5QQwAAAIC7Fema5Mcee0wffPBBUZ5SP//8sx577DFVqlRJ5cqV05133qnNmzebxw3D0Lhx4xQWFiZfX1+1a9dOO3fudDpHdna2hg4dqqCgIPn5+Sk6OlrHjh1zqklPT1dsbKzsdrvsdrtiY2OVkZFRpNcCAACAkqFIQ/KGDRvk4+NTZOdLT09XmzZt5Onpqa+//lq7du3SW2+9pQoVKpg1kyZN0uTJkzVt2jQlJSUpNDRUnTp10tmzZ82auLg4LVmyRAsXLtS6det07tw5RUVFKS8vz6yJiYlRcnKyEhISlJCQoOTkZD52GwAA4BZlMwzDuNYHPfDAA073DcPQiRMn9MMPP+jFF1/U2LFji6S55557Tv/973/1/fffF3rcMAyFhYUpLi5OY8aMkXRp1jgkJESvv/66nnzySTkcDlWuXFlz587Vww8/LEk6fvy4wsPDtWzZMnXp0kUpKSlq0KCBEhMT1bJlS0lSYmKiIiMjtXv3btWtW7fQ58/OzlZ2drZ5PzMzU+Hh4XI4HAoICCiS1+BWYBvP3tq4OYyx1/zrDgBQymRmZsput/9uXruumeSCJQkFt8DAQLVr107Lli0rsoAsSUuXLlWLFi30l7/8RcHBwWratKnee+898/jBgweVmpqqzp07m2Pe3t5q27at1q9fL0navHmzcnNznWrCwsLUqFEjs2bDhg2y2+1mQJakVq1ayW63mzWFmThxotPrEB4eXmTXDgAAAPe5rjfuffjhh0XdR6EOHDigmTNnavjw4fr73/+uTZs2adiwYfL29lafPn2UmpoqSQoJCXF6XEhIiA4fPixJSk1NlZeXlypWrOhSU/D41NRUBQcHuzx/cHCwWVOY+Ph4DR8+3LxfMJMMAACAku26QnKBzZs3KyUlRTabTQ0aNFDTpk2Lqi9JUn5+vlq0aKEJEyZIkpo2baqdO3dq5syZ6tOnj1ln3bPZMIzf/Xhsa01h9b93Hm9vb3l7e1/VtQAAAKDkuK7lFmlpabrvvvt01113adiwYRoyZIiaN2+uDh066NSpU0XWXJUqVdSgQQOnsfr16+vIkSOSpNDQUElyme1NS0szZ5dDQ0OVk5Oj9PT0K9acPHnS5flPnTrlMksNAACA0u+6QvLQoUOVmZmpnTt36syZM0pPT9eOHTuUmZmpYcOGFVlzbdq00Z49e5zG9u7dq+rVq0uSIiIiFBoaqhUrVpjHc3JytGbNGrVu3VqS1Lx5c3l6ejrVnDhxQjt27DBrIiMj5XA4tGnTJrNm48aNcjgcZg0AAABuHde13CIhIUHffvut6tevb441aNBA06dPd3qD3B/17LPPqnXr1powYYJ69+6tTZs26d1339W7774r6dISibi4OE2YMEG1a9dW7dq1NWHCBJUrV04xMTGSLr3JsH///hoxYoQqVaqkwMBAjRw5Uo0bN1bHjh0lXZqd7tq1qwYMGKDZs2dLkgYOHKioqKjL7mwBAACA0uu6QnJ+fr48PT1dxj09PZWfn/+Hmypw1113acmSJYqPj9fLL7+siIgITZ06VY8++qhZM3r0aGVlZWnQoEFKT09Xy5YttXz5cvn7+5s1U6ZMUdmyZdW7d29lZWWpQ4cOmjNnjjw8PMyaefPmadiwYWbIj46O1rRp04rsWgAAAFByXNc+yX/+85+VkZGhBQsWKCwsTNKlT8Z79NFHVbFiRS1ZsqTIGy0JrnbfPThjn2TcLOyTDAC4ofskT5s2TWfPnlWNGjVUq1Yt3X777YqIiNDZs2f1zjvvXHfTAAAAQHFwXcstwsPDtWXLFq1YsUK7d++WYRhq0KCBucYXAAAAKMmuaSZ51apVatCggTIzMyVJnTp10tChQzVs2DDdddddatiw4WU/QhoAAAAoKa4pJE+dOlUDBgwodP2G3W7Xk08+qcmTJxdZcwAAAIA7XFNI3rZtm7p27XrZ4507d9bmzZv/cFMAAACAO11TSD558mShW78VKFu2bJF+4h4AAADgDtcUkqtWraoff/zxsse3b9+uKlWq/OGmAAAAAHe6ppDcvXt3vfTSS7pw4YLLsaysLI0dO1ZRUVFF1hwAAADgDtf0YSInT55Us2bN5OHhoSFDhqhu3bqy2WxKSUnR9OnTlZeXpy1btigkJORG9lxs8WEi14cPE8HNwoeJAACuNq9d0z7JISEhWr9+vZ5++mnFx8erIF/bbDZ16dJFM2bMuGUDMgAAAEqPa/4wkerVq2vZsmVKT0/Xvn37ZBiGateurYoVK96I/gAAAICb7ro+cU+SKlasqLvuuqsoewEAAACKhWt64x4AAABwKyAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYlKiQPHHiRNlsNsXFxZljhmFo3LhxCgsLk6+vr9q1a6edO3c6PS47O1tDhw5VUFCQ/Pz8FB0drWPHjjnVpKenKzY2Vna7XXa7XbGxscrIyLgJVwUAAIDipsSE5KSkJL377rtq0qSJ0/ikSZM0efJkTZs2TUlJSQoNDVWnTp109uxZsyYuLk5LlizRwoULtW7dOp07d05RUVHKy8sza2JiYpScnKyEhAQlJCQoOTlZsbGxN+36AAAAUHyUiJB87tw5Pfroo3rvvfdUsWJFc9wwDE2dOlXPP/+8HnjgATVq1Ej/+te/9Ouvv2r+/PmSJIfDoX/+859666231LFjRzVt2lQff/yxfvzxR3377beSpJSUFCUkJOj9999XZGSkIiMj9d577+nLL7/Unj173HLNAAAAcJ8SEZIHDx6sHj16qGPHjk7jBw8eVGpqqjp37myOeXt7q23btlq/fr0kafPmzcrNzXWqCQsLU6NGjcyaDRs2yG63q2XLlmZNq1atZLfbzZrCZGdnKzMz0+kGAACAkq+suxv4PQsXLtSWLVuUlJTkciw1NVWSFBIS4jQeEhKiw4cPmzVeXl5OM9AFNQWPT01NVXBwsMv5g4ODzZrCTJw4UePHj7+2CwIAAECxV6xnko8ePapnnnlGH3/8sXx8fC5bZ7PZnO4bhuEyZmWtKaz+984THx8vh8Nh3o4ePXrF5wQAAEDJUKxD8ubNm5WWlqbmzZurbNmyKlu2rNasWaO3335bZcuWNWeQrbO9aWlp5rHQ0FDl5OQoPT39ijUnT550ef5Tp065zFL/lre3twICApxuAAAAKPmKdUju0KGDfvzxRyUnJ5u3Fi1a6NFHH1VycrJq1qyp0NBQrVixwnxMTk6O1qxZo9atW0uSmjdvLk9PT6eaEydOaMeOHWZNZGSkHA6HNm3aZNZs3LhRDofDrAEAAMCto1ivSfb391ejRo2cxvz8/FSpUiVzPC4uThMmTFDt2rVVu3ZtTZgwQeXKlVNMTIwkyW63q3///hoxYoQqVaqkwMBAjRw5Uo0bNzbfCFi/fn117dpVAwYM0OzZsyVJAwcOVFRUlOrWrXsTrxgAAADFQbEOyVdj9OjRysrK0qBBg5Senq6WLVtq+fLl8vf3N2umTJmismXLqnfv3srKylKHDh00Z84ceXh4mDXz5s3TsGHDzF0woqOjNW3atJt+PQAAAHA/m2EYhrubKC0yMzNlt9vlcDhYn3wNbOOv/CZLoKgYY/l1BwC3uqvNa8V6TTIAAADgDoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABbFOiRPnDhRd911l/z9/RUcHKxevXppz549TjWGYWjcuHEKCwuTr6+v2rVrp507dzrVZGdna+jQoQoKCpKfn5+io6N17Ngxp5r09HTFxsbKbrfLbrcrNjZWGRkZN/oSAQAAUAwV65C8Zs0aDR48WImJiVqxYoUuXryozp076/z582bNpEmTNHnyZE2bNk1JSUkKDQ1Vp06ddPbsWbMmLi5OS5Ys0cKFC7Vu3TqdO3dOUVFRysvLM2tiYmKUnJyshIQEJSQkKDk5WbGxsTf1egEAAFA82AzDMNzdxNU6deqUgoODtWbNGt17770yDENhYWGKi4vTmDFjJF2aNQ4JCdHrr7+uJ598Ug6HQ5UrV9bcuXP18MMPS5KOHz+u8PBwLVu2TF26dFFKSooaNGigxMREtWzZUpKUmJioyMhI7d69W3Xr1r2q/jIzM2W32+VwOBQQEHBjXoRSyDbe5u4WcIswxpaYX3cAgBvkavNasZ5JtnI4HJKkwMBASdLBgweVmpqqzp07mzXe3t5q27at1q9fL0navHmzcnNznWrCwsLUqFEjs2bDhg2y2+1mQJakVq1ayW63mzWFyc7OVmZmptMNAAAAJV+JCcmGYWj48OG655571KhRI0lSamqqJCkkJMSpNiQkxDyWmpoqLy8vVaxY8Yo1wcHBLs8ZHBxs1hRm4sSJ5hpmu92u8PDw679AAAAAFBslJiQPGTJE27dv14IFC1yO2WzOf643DMNlzMpaU1j9750nPj5eDofDvB09evT3LgMAAAAlQIkIyUOHDtXSpUu1evVq3XbbbeZ4aGioJLnM9qalpZmzy6GhocrJyVF6evoVa06ePOnyvKdOnXKZpf4tb29vBQQEON0AAABQ8hXrkGwYhoYMGaLFixdr1apVioiIcDoeERGh0NBQrVixwhzLycnRmjVr1Lp1a0lS8+bN5enp6VRz4sQJ7dixw6yJjIyUw+HQpk2bzJqNGzfK4XCYNQAAALh1lHV3A1cyePBgzZ8/X//5z3/k7+9vzhjb7Xb5+vrKZrMpLi5OEyZMUO3atVW7dm1NmDBB5cqVU0xMjFnbv39/jRgxQpUqVVJgYKBGjhypxo0bq2PHjpKk+vXrq2vXrhowYIBmz54tSRo4cKCioqKuemcLAAAAlB7FOiTPnDlTktSuXTun8Q8//FD9+vWTJI0ePVpZWVkaNGiQ0tPT1bJlSy1fvlz+/v5m/ZQpU1S2bFn17t1bWVlZ6tChg+bMmSMPDw+zZt68eRo2bJi5C0Z0dLSmTZt2Yy8QAAAAxVKJ2ie5uGOf5OvDPsm4WdgnGQBQKvdJBgAAAG4GQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0IyAAAAYEFIBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMAAAAWBCSAQAAAAtCMgAAAGBBSAYAAAAsCMkAAACABSEZAAAAsCAkAwAAABaEZAAAAMCCkAwAAABYEJIBAAAAC0KyxYwZMxQRESEfHx81b95c33//vbtbAgAAwE1W1t0NFCeffPKJ4uLiNGPGDLVp00azZ89Wt27dtGvXLlWrVs3d7QEASgqbzd0d4FZhGO7uoNSyGQavboGWLVuqWbNmmjlzpjlWv3599erVSxMnTnSpz87OVnZ2tnnf4XCoWrVqOnr0qAICAm5Kz6WBfaLd3S3gFuGId7i7Bdwq7Pxew03i4PfatcrMzFR4eLgyMjJkv8LPKjPJ/ycnJ0ebN2/Wc8895zTeuXNnrV+/vtDHTJw4UePHj3cZDw8PvyE9Avhj7K8RXACUMvyD7LqdPXuWkHw1fvnlF+Xl5SkkJMRpPCQkRKmpqYU+Jj4+XsOHDzfv5+fn68yZM6pUqZJs/KkNN1DBv4L5qwWA0oLfa7hZDMPQ2bNnFRYWdsU6QrKFNdwahnHZwOvt7S1vb2+nsQoVKtyo1gAXAQEB/M8EQKnC7zXcDFeaQS7A7hb/JygoSB4eHi6zxmlpaS6zywAAACjdCMn/x8vLS82bN9eKFSucxlesWKHWrVu7qSsAAAC4A8stfmP48OGKjY1VixYtFBkZqXfffVdHjhzRU0895e7WACfe3t4aO3asy3IfACip+L2G4oYt4CxmzJihSZMm6cSJE2rUqJGmTJmie++9191tAQAA4CYiJAMAAAAWrEkGAAAALAjJAAAAgAUhGQAAALAgJAMAAAAWhGQAAADAgpAMlCA5OTnas2ePLl686O5WAAAo1QjJQAnw66+/qn///ipXrpwaNmyoI0eOSJKGDRum1157zc3dAcD18fDwUFpamsv46dOn5eHh4YaOgP8hJAMlQHx8vLZt26bvvvtOPj4+5njHjh31ySefuLEzALh+l/uohuzsbHl5ed3kbgBnfCw1UAJ8/vnn+uSTT9SqVSvZbDZzvEGDBtq/f78bOwOAa/f2229Lkmw2m95//32VL1/ePJaXl6e1a9eqXr167moPkERIBkqEU6dOKTg42GX8/PnzTqEZAEqCKVOmSLo0kzxr1iynpRVeXl6qUaOGZs2a5a72AEmEZKBEuOuuu/TVV19p6NChkmQG4/fee0+RkZHubA0ArtnBgwclSe3bt9fixYtVsWJFN3cEuCIkAyXAxIkT1bVrV+3atUsXL17UP/7xD+3cuVMbNmzQmjVr3N0eAFyX1atXu7sF4LJsxuVWzQMoVn788Ue9+eab2rx5s/Lz89WsWTONGTNGjRs3dndrAHBd8vLyNGfOHK1cuVJpaWnKz893Or5q1So3dQYQkgEAgJsMGTJEc+bMUY8ePVSlShWX91gUrF0G3IGQDJQQ+fn52rdvX6GzLffee6+bugKA6xcUFKSPPvpI3bt3d3crgAvWJAMlQGJiomJiYnT48GGXfUVtNpvy8vLc1BkAXD8vLy/dfvvt7m4DKBQzyUAJcOedd6pOnToaP358oX+StNvtbuoMAK7fW2+9pQMHDmjatGlsZ4lih5AMlAB+fn7atm0bMy4ASpX7779fq1evVmBgoBo2bChPT0+n44sXL3ZTZwDLLYASoWXLltq3bx8hGUCpUqFCBd1///3ubgMoFDPJQAmwZMkSvfDCCxo1apQaN27sMtvSpEkTN3UGAEDpREgGSoAyZcq4jNlsNhmGwRv3AJRoFy9e1Hfffaf9+/crJiZG/v7+On78uAICAlS+fHl3t4dbGMstgBKg4CNcAaA0OXz4sLp27aojR44oOztbnTp1kr+/vyZNmqQLFy5o1qxZ7m4RtzBCMlACVK9e3d0tAECRe+aZZ9SiRQtt27ZNlSpVMsfvv/9+PfHEE27sDCAkA8XW0qVL1a1bN3l6emrp0qVXrI2Ojr5JXQFA0Vm3bp3++9//ysvLy2m8evXq+vnnn93UFXAJIRkopnr16qXU1FQFBwerV69el61jTTKAkio/P7/Q31/Hjh2Tv7+/GzoC/sf13UAAioX8/HwFBweb/325GwEZQEnVqVMnTZ061bxvs9l07tw5jR07lo+qhtuxuwUAAHCL48ePq3379vLw8NBPP/2kFi1a6KefflJQUJDWrl1rThQA7kBIBkqAl19++YrHX3rppZvUCQAUraysLC1YsEBbtmxRfn6+mjVrpkcffVS+vr7ubg23OEIyUAI0bdrU6X5ubq4OHjyosmXLqlatWtqyZYubOgMAoHTijXtACbB161aXsczMTPXr14+PdAVQovzebj2/xc49cCdmkoESbMeOHYqKitKhQ4fc3QoAXJXCPkG0MOzcA3djJhkowTIyMuRwONzdBgBctfz8fHe3AFwVQjJQArz99ttO9w3D0IkTJzR37lx17drVTV0BAFB6sdwCKAEiIiKc7pcpU0aVK1fWfffdp/j4eDbdB1AisXMPijNCMgAAcAt27kFxxnILAADgFuzcg+KMmWSgBDh//rxee+01rVy5UmlpaS5vfDlw4ICbOgOAosfOPSgOmEkGSoAnnnhCa9asUWxsrKpUqSKbzebulgDghmHnHhQHhGSgBPj666/11VdfqU2bNu5uBQCKDDv3oDgjJAMlQMWKFRUYGOjuNgCgSE2ZMsXpfsHOPX379lV8fLybugIuYU0yUAJ8/PHH+s9//qN//etfKleunLvbAQCg1CMkAyVA06ZNtX//fhmGoRo1asjT09PpONskAQBQtFhuAZQAvXr1cncLAFAkHnjggauuXbx48Q3sBLgyQjJQAowdO9bdLQBAkbDb7eZ/G4ahJUuWyG63q0WLFpKkzZs3KyMj45rCNHAjsNwCKCEyMjL02Wefaf/+/Ro1apQCAwO1ZcsWhYSEqGrVqu5uDwCu2ZgxY3TmzBnNmjVLHh4ekqS8vDwNGjRIAQEBeuONN9zcIW5lhGSgBNi+fbs6duwou92uQ4cOac+ePapZs6ZefPFFHT58WB999JG7WwSAa1a5cmWtW7dOdevWdRrfs2ePWrdurdOnT7upM0Aq4+4GAPy+4cOHq1+/fvrpp5/k4+Njjnfr1k1r1651Y2cAcP0uXryolJQUl/GUlBSXTxYFbjbWJAMlQFJSkmbPnu0yXrVqVaWmprqhIwD44x5//HH97W9/0759+9SqVStJUmJiol577TU9/vjjbu4OtzpCMlAC+Pj4KDMz02V8z549qly5shs6AoA/7s0331RoaKimTJmiEydOSJKqVKmi0aNHa8SIEW7uDrc61iQDJcDAgQN16tQpffrppwoMDNT27dvl4eGhXr166d5779XUqVPd3SIA/CEFEwEBAQFu7gS4hJAMlACZmZnq3r27du7cqbNnzyosLEypqalq1aqVvv76a/n5+bm7RQAAShVCMlCCrF69Wps3b1Z+fr6aNWumjh07urslALhuERERstlslz1+4MCBm9gN4Iw1yUAxlpWVpZUrVyoqKkqStHz5cmVnZ0uSli1bpuXLl+vll1922vECAEqKuLg4p/u5ubnaunWrEhISNGrUKPc0BfwfZpKBYmz27Nn68ssv9cUXX0iS/P391bBhQ/n6+kqSdu/erdGjR+vZZ591Z5sAUKSmT5+uH374QR9++KG7W8EtjJAMFGP33nuvnn32Wd1///2SLoXkbdu2qWbNmpKkjz/+WNOnT9eGDRvc2SYAFKkDBw7ozjvvLHRXH+Bm4cNEgGJs7969qlOnjnnfx8dHZcr878f27rvv1q5du9zRGgDcMJ999pkCAwPd3QZucaxJBooxh8OhsmX/92N66tQpp+P5+fnmGmUAKGmaNm3q9MY9wzCUmpqqU6dOacaMGW7sDCAkA8Xabbfdph07dqhu3bqFHt++fbtuu+22m9wVABSNXr16Od0vU6aMKleurHbt2qlevXruaQr4P6xJBoqxZ555Rt9++602b97ssoNFVlaWWrRooY4dO+of//iHmzoEAKB0IiQDxdjJkyd15513ysvLS0OGDFGdOnVks9m0e/duTZs2TRcvXtTWrVsVEhLi7lYB4A/JyspSbm6u0xifvgd3IiQDxdzBgwf19NNPa8WKFSr4cbXZbOrUqZNmzJhh7nQBACXN+fPnNWbMGH366ac6ffq0y/G8vDw3dAVcQkgGSogzZ85o3759kqTbb7+dd34DKPEGDx6s1atX6+WXX1afPn00ffp0/fzzz5o9e7Zee+01Pfroo+5uEbcwQjIAAHCLatWq6aOPPlK7du0UEBCgLVu26Pbbb9fcuXO1YMECLVu2zN0t4hbGPskAAMAtzpw5o4iICEmX1h+fOXNGknTPPfdo7dq17mwNICQDAAD3qFmzpg4dOiRJatCggT799FNJ0hdffKEKFSq4rzFALLcAAABuMmXKFHl4eGjYsGFavXq1evTooby8PF28eFGTJ0/WM8884+4WcQsjJAMAgGLhyJEj+uGHH1SrVi3dcccd7m4HtzhCMgAAuOlyc3PVuXNnzZ49W3Xq1HF3O4AL1iQDAICbztPTUzt27JDNZnN3K0ChCMkAAMAt+vTpo3/+85/ubgMoVFl3NwAAAG5NOTk5ev/997VixQq1aNFCfn5+TscnT57sps4AQjIAALjJDhw4oBo1amjHjh1q1qyZJGnv3r1ONSzDgLvxxj0AAHBTeXh46MSJEwoODpYkPfzww3r77bcVEhLi5s6A/2FNMgAAuKms83Nff/21zp8/76ZugMIRkgEAgFvxR20UR4RkAABwU9lsNpc1x6xBRnHDG/cAAMBNZRiG+vXrJ29vb0nShQsX9NRTT7nsbrF48WJ3tAdIIiQDAICbrG/fvk73H3vsMTd1Alweu1sAAAAAFqxJBgAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkALjF2Ww2ff755+5uAwCKFUIyAJRyqampGjp0qGrWrClvb2+Fh4erZ8+eWrlypbtbA4Bii32SAaAUO3TokNq0aaMKFSpo0qRJatKkiXJzc/XNN99o8ODB2r17t7tbBIBiiZlkACjFBg0aJJvNpk2bNumhhx5SnTp11LBhQw0fPlyJiYmFPmbMmDGqU6eOypUrp5o1a+rFF19Ubm6ueXzbtm1q3769/P39FRAQoObNm+uHH36QJB0+fFg9e/ZUxYoV5efnp4YNG2rZsmU35VoBoCgxkwwApdSZM2eUkJCgV1991eXjfiWpQoUKhT7O399fc+bMUVhYmH788UcNGDBA/v7+Gj16tCTp0UcfVdOmTTVz5kx5eHgoOTlZnp6ekqTBgwcrJydHa9eulZ+fn3bt2qXy5cvfsGsEgBuFkAwApdS+fftkGIbq1at3TY974YUXzP+uUaOGRowYoU8++cQMyUeOHNGoUaPM89auXdusP3LkiB588EE1btxYklSzZs0/ehkA4BYstwCAUsowDEmXdq+4Fp999pnuuecehYaGqnz58nrxxRd15MgR8/jw4cP1xBNPqGPHjnrttde0f/9+89iwYcP0yiuvqE2bNho7dqy2b99eNBcDADcZIRkASqnatWvLZrMpJSXlqh+TmJioRx55RN26ddOXX36prVu36vnnn1dOTo5ZM27cOO3cuVM9evTQqlWr1KBBAy1ZskSS9MQTT+jAgQOKjY3Vjz/+qBYtWuidd94p8msDgBvNZhRMNQAASp1u3brpxx9/1J49e1zWJWdkZKhChQqy2WxasmSJevXqpbfeekszZsxwmh1+4okn9NlnnykjI6PQ5/jrX/+q8+fPa+nSpS7H4uPj9dVXXzGjDKDEYSYZAEqxGTNmKC8vT3fffbcWLVqkn376SSkpKXr77bcVGRnpUn/77bfryJEjWrhwofbv36+3337bnCWWpKysLA0ZMkTfffedDh8+rP/+979KSkpS/fr1JUlxcXH65ptvdPDgQW3ZskWrVq0yjwFAScIb9wCgFIuIiNCWLVv06quvasSIETpx4oQqV66s5s2ba+bMmS71f/7zn/Xss89qyJAhys7OVo8ePfTiiy9q3LhxkiQPDw+dPn1affr00cmTJxUUFKQHHnhA48ePlyTl5eVp8ODBOnbsmAICAtS1a1dNmTLlZl4yABQJllsAAAAAFiy3AAAAACwIyQAAAIAFIRkAAACwICQDAAAAFoRkAAAAwIKQDAAAAFgQkgEAAAALQjIAAABgQUgGAAAALAjJAAAAgAUhGQAAALD4/wZV6CfGhltwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "class_counts.plot(kind = 'bar', color = ['green', 'red'])\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Genuine v/s Fraudulent transactions')\n",
    "plt.xticks([0,1], ['Genuine', 'Fraudulent'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a041eab",
   "metadata": {},
   "source": [
    "### 5. Using the Standard Scaler module, normalize the amount column and store the new values in the NormalizedAmount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33373f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>NormalizedAmount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.482873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.334272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.756668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V22       V23       V24       V25       V26  \\\n",
       "0  0.098698  0.363787  ...  0.277838 -0.110474  0.066928  0.128539 -0.189115   \n",
       "1  0.085102 -0.255425  ... -0.638672  0.101288 -0.339846  0.167170  0.125895   \n",
       "2  0.247676 -1.514654  ...  0.771679  0.909412 -0.689281 -0.327642 -0.139097   \n",
       "3  0.377436 -1.387024  ...  0.005274 -0.190321 -1.175575  0.647376 -0.221929   \n",
       "4 -0.270533  0.817739  ...  0.798278 -0.137458  0.141267 -0.206010  0.502292   \n",
       "\n",
       "        V27       V28  Amount  Class  NormalizedAmount  \n",
       "0  0.133558 -0.021053  149.62    0.0          0.482873  \n",
       "1 -0.008983  0.014724    2.69    0.0         -0.334272  \n",
       "2 -0.055353 -0.059752  378.66    0.0          1.756668  \n",
       "3  0.062723  0.061458  123.50    0.0          0.337607  \n",
       "4  0.219422  0.215153   69.99    0.0          0.040014  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['NormalizedAmount'] = scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013ad35",
   "metadata": {},
   "source": [
    "### 6. Split the dataset in train and test set and have a 70:30 split ratio for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "447fadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X= df.drop(['Class'], axis = 1)\n",
    "y = df['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f9517ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Now use a decision tree and random forest model for training on top of the train set.\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5341e4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cdbda84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Compare the predictions of both models using predict.\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f413e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_RF = RF.predict(X_test)\n",
    "y_pred_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57f03d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics._classification.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Compare the accuracy of both models using score().\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "accuracy_score_dt = accuracy_score(y_test, y_pred_dt)\n",
    "accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e81aaf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3484\n",
      "         1.0       0.78      0.88      0.82        16\n",
      "\n",
      "    accuracy                           1.00      3500\n",
      "   macro avg       0.89      0.94      0.91      3500\n",
      "weighted avg       1.00      1.00      1.00      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "142cba80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991428571428571"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score_RF = accuracy_score(y_test, y_pred)\n",
    "accuracy_score_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "44f076a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      3484\n",
      "         1.0       0.93      0.88      0.90        16\n",
      "\n",
      "    accuracy                           1.00      3500\n",
      "   macro avg       0.97      0.94      0.95      3500\n",
      "weighted avg       1.00      1.00      1.00      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "470df679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model:\n",
      "Accuracy: 0.9982857142857143\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.875\n",
      "F1 Score: 0.823529411764706\n",
      "\n",
      "Random Forest Model:\n",
      "Accuracy: 0.9991428571428571\n",
      "Precision: 0.9333333333333333\n",
      "Recall: 0.875\n",
      "F1 Score: 0.9032258064516129\n",
      "\n",
      "Random Forest Model has the highest accuracy.\n"
     ]
    }
   ],
   "source": [
    "# 10. Check the performance matrix of both models and compare which model is having the highest performance.\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate performance metrics for the Decision Tree model\n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "dt_recall = recall_score(y_test,y_pred_dt)\n",
    "dt_f1_score = f1_score(y_test, y_pred_dt)\n",
    "\n",
    "# Calculate performance metrics for the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_RF)\n",
    "rf_precision = precision_score(y_test,  y_pred_RF)\n",
    "rf_recall = recall_score(y_test,  y_pred_RF)\n",
    "rf_f1_score = f1_score(y_test,  y_pred_RF)\n",
    "\n",
    "# Compare the performance metrics\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", dt_accuracy)\n",
    "print(\"Precision:\", dt_precision)\n",
    "print(\"Recall:\", dt_recall)\n",
    "print(\"F1 Score:\", dt_f1_score)\n",
    "\n",
    "print(\"\\nRandom Forest Model:\")\n",
    "print(\"Accuracy:\", rf_accuracy)\n",
    "print(\"Precision:\", rf_precision)\n",
    "print(\"Recall:\", rf_recall)\n",
    "print(\"F1 Score:\", rf_f1_score)\n",
    "\n",
    "# Determine which model has the highest performance based on the metrics\n",
    "if dt_accuracy > rf_accuracy:\n",
    "    print(\"\\nDecision Tree Model has the highest accuracy.\")\n",
    "else:\n",
    "    print(\"\\nRandom Forest Model has the highest accuracy.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c044cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
